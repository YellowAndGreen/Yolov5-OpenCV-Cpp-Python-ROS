# Yolov5-OpenCV-Cpp-Python-ROS

ä½¿ç”¨OpenCV 4.5.4æ¨ç†YOLOv5æ¨¡å‹ï¼Œåˆ†åˆ«ä½¿ç”¨C++ï¼ŒPythonå’ŒROSå®ç°ã€‚


**åŸºäº[yolov5-opencv-cpp-python](https://github.com/doleron/yolov5-opencv-cpp-python)ä¿®æ”¹ã€‚**
åœ¨åŸä»£ç çš„åŸºç¡€ä¸Šä½¿ç”¨CMakeç¼–è¯‘ï¼ˆèƒ½å¤Ÿæ›´æ–¹ä¾¿çš„å®šä¹‰ç¨‹åºè·¯å¾„ï¼‰ï¼Œå¹¶ä¸”åŠ å…¥äº†å¯¹ROSä¼ å…¥å›¾ç‰‡çš„æ”¯æŒã€‚

## ä»£ç è§£é‡Š
+ å˜é‡**net_path**å®šä¹‰äº†onnxç½‘ç»œæ¨¡å‹è·¯å¾„.
+ å˜é‡ **class_path**å®šä¹‰äº†åˆ†ç±»æ–‡ä»¶çš„è·¯å¾„.
+ ROSèŠ‚ç‚¹è®¢é˜…**/image**è¯é¢˜æ¥è·å–è¾“å…¥å›¾åƒ.
> NOTE: The code depends on the output dimension of your network model, which means the variables **dimensions and rows** in ros.cpp should be the exact same size of output dimensions.
> æ³¨æ„: ç½‘ç»œæ¨ç†çš„è®¡ç®—å–å†³äºç½‘ç»œæ¨¡å‹çš„è¾“å‡ºç»´åº¦, ä¹Ÿå°±æ˜¯è¯´ros.cppä¸­çš„å˜é‡**dimensions and rows**åº”è¯¥ä¸å…¶ä¸€è‡´.

## ç¯å¢ƒé…ç½®
- ä»»ä½•Linux OS (åœ¨Ubuntu 18.04ä¸Šæµ‹è¯•)
- OpenCV 4.5.4+
- Python 3.7+(å¯é€‰)
- GCC 9.0+(å¯é€‰)
- ROS melodic(å¯é€‰)

**æ³¨æ„**!!! å…ˆäº4.5.4çš„OpenCVç‰ˆæœ¬ä¸ä¼šæ­£å¸¸è¿è¡Œã€‚

## ä½¿ç”¨ROS/C++æ¨ç†

C++/ROSä»£ç åœ¨[Yolo_ROS/ros.cpp](Yolo_ROS/ros.cpp)ã€‚

```bash
git clone https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS.git
cd Yolov5-OpenCV-Cpp-Python-ROS/Yolo_ROS
mkdir build && cd build
cmake ../
make
./yolo_ros
```


## ä½¿ç”¨pythonæ¨ç†

Pythonä»£ç åœ¨[python/yolo.py](python/yolo.py).

```bash
git clone https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS.git
cd Yolov5-OpenCV-Cpp-Python-ROS
python python/yolo.py 
```

ä½¿ç”¨GPUè¿è¡Œï¼š

```bash
git clone https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS.git
cd Yolov5-OpenCV-Cpp-Python-ROS
python python/yolo.py cuda
python python/yolo-tiny.py cuda
```

## ä½¿ç”¨C++æ¨ç†

C++ä»£ç åœ¨[cpp/yolo.cpp](cpp/yolo.cpp).

```bash
git clone https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS.git
cd Yolov5-OpenCV-Cpp-Python-ROS/cpp
mkdir build && cd build
cmake ../
make
./yolo_example
```

## å¯¼å‡ºYolov5 æ¨¡å‹åˆ°onnxæ ¼å¼

https://github.com/ultralytics/yolov5/issues/251

æˆ‘çš„æŒ‡ä»¤æ˜¯:

```bash
git clone https://github.com/ultralytics/yolov5
cd yolov5
pip install -r requirements.txt
```
ç„¶åè½¬æ¢æ¨¡å‹:

```bash
$ python3 export.py --weights yolov5n.pt --img 640 --include onnx
export: data=data/coco128.yaml, weights=['yolov5n.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']
YOLOv5 ğŸš€ v6.0-192-g436ffc4 torch 1.10.1+cu102 CPU

Fusing layers... 
Model Summary: 213 layers, 1867405 parameters, 0 gradients

PyTorch: starting from yolov5n.pt (4.0 MB)

ONNX: starting export with onnx 1.10.2...
/home/user/workspace/smartcam/yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if self.onnx_dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:
ONNX: export success, saved as yolov5n.onnx (7.9 MB)

Export complete (1.33s)
Results saved to /home/doleron/workspace/smartcam/yolov5
Visualize with https://netron.app
Detect with `python detect.py --weights yolov5n.onnx` or `model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.onnx')
Validate with `python val.py --weights yolov5n.onnx`
$ 
```
